{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare keypoints metrics on the original, SR and upscaled prediction iamges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import keypointrcnn_resnet50_fpn, KeypointRCNN_ResNet50_FPN_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeypointRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(640, 672, 704, 736, 768, 800), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "    (keypoint_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (keypoint_head): KeypointRCNNHeads(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "    )\n",
       "    (keypoint_predictor): KeypointRCNNPredictor(\n",
       "      (kps_score_lowres): ConvTranspose2d(512, 17, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.detection.keypointrcnn_resnet50_fpn(weights=KeypointRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load pyspng. Defaulting to pillow image backend.\n",
      "Dataset loaded from: /datadrive/FDF/dataset/val. Number of samples:6531\n"
     ]
    }
   ],
   "source": [
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "sys.path.insert(0, '/datadrive/facediffusion')\n",
    "from fdh256_dataset import FDF256Dataset\n",
    "\n",
    "dataset_path = '/datadrive/FDF/dataset/val'\n",
    "dataset = FDF256Dataset(dirpath=dataset_path, load_keypoints=True, load_impath=True)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=22,\n",
    "                            prefetch_factor=2, persistent_workers=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = '/datadrive/facediffusion/Coginfocom/images-ema' if EMA else '/datadrive/facediffusion/Coginfocom/images'\n",
    "sr_path = '/datadrive/facediffusion/Coginfocom/DFDNet-SR-Coginfocom-EMA' if EMA else '/datadrive/facediffusion/Coginfocom/DFDNet-SR-Coginfocom'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotations\n",
    "\n",
    "The annotation tensor is a 7x2 size tensor where the keypoints are:\n",
    "- nose\n",
    "- left eye\n",
    "- right eye\n",
    "- left ear\n",
    "- right ear\n",
    "- left shoulder\n",
    "- right shoulder\n",
    "\n",
    "The model output tensor is a 17x3 tensor, where the coordinates are the x, y, and visibility (0 is invisible, 1 is visible). The keypoints are:\n",
    "- nose\n",
    "- left eye\n",
    "- right eye\n",
    "- left ear\n",
    "- right ear\n",
    "- left shoulder\n",
    "- right shoulder\n",
    "- left elbow\n",
    "- right elbow\n",
    "- left wrist\n",
    "- right wrist\n",
    "- left hip\n",
    "- right hip\n",
    "- left knee\n",
    "- right knee\n",
    "- left ankle\n",
    "- right ankle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://learnopencv.com/human-pose-estimation-using-keypoint-rcnn-in-pytorch/, rewritten a bit\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def filter_keypoints_per_person(all_keypoints, all_scores, confs, keypoint_threshold=2, conf_threshold=0.9):\n",
    "    # iterate for every person detected\n",
    "    for person_id in range(len(all_keypoints)):\n",
    "      # check the confidence score of the detected person\n",
    "      if confs[person_id]>conf_threshold:\n",
    "        # grab the keypoint-locations for the detected person\n",
    "        keypoints:Tensor = all_keypoints[person_id, ...]\n",
    "        # grab the keypoint-scores for the keypoints\n",
    "        scores: Tensor = all_scores[person_id, ...]\n",
    "        # iterate for every keypoint-score\n",
    "        for kp in range(len(scores)):\n",
    "            # check the confidence score of detected keypoint\n",
    "            if scores[kp] < keypoint_threshold:\n",
    "                # convert the keypoint float-array to a python-list of integers\n",
    "                keypoints[kp, 2] = 0\n",
    "        return keypoints # return the first person with enough confidence\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\displaystyle \\mathrm{DE}(x, y, xhat, yhat, w) = \\frac{\\sqrt{\\left( x - xhat \\right)^{{2}} + \\left( y - yhat \\right)^{{2}}}}{w} $$"
      ],
      "text/plain": [
       "<latexify.frontend.LatexifiedFunction at 0x7f0dc0420b50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import latexify\n",
    "import math\n",
    "\n",
    "@latexify.with_latex\n",
    "def DE(x, y, xhat, yhat, w) -> float:\n",
    "    return math.sqrt((x - xhat)**2 + (y - yhat)**2) / w\n",
    "\n",
    "DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(truth, pred):\n",
    "    sum = 0.0\n",
    "    N = 0\n",
    "    for i in range(0, 7):\n",
    "        x, y, v = truth[i]\n",
    "        x_hat, y_hat, v_hat = pred[i]\n",
    "        if v == 0 or v_hat == 0:\n",
    "            continue\n",
    "        sum += ((x - x_hat)**2 + (y - y_hat)**2)\n",
    "        N += 1\n",
    "    \n",
    "    if N == 0:\n",
    "        return None\n",
    "    \n",
    "    return math.sqrt(sum / float(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "kpt_oks_sigmas = np.array([.26, .25, .25, .35, .35, .79, .79])/10.0 * 256# from https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/cocoeval.py#L523\n",
    "\n",
    "\n",
    "def OKS(y_true, y_pred, visibility, bbox_area: float):\n",
    "    SCALE = bbox_area / float(256**2)\n",
    "    # Compute the L2/Euclidean Distance\n",
    "    distances = np.linalg.norm(y_pred - y_true, axis=-1)\n",
    "    # Compute the exponential part of the equation\n",
    "    exp_vector = np.exp(-(distances**2) / (2 * (SCALE**2) * (kpt_oks_sigmas**2)))\n",
    "    # The numerator expression\n",
    "    numerator = np.dot(exp_vector, visibility.astype(bool).astype(int))\n",
    "    # The denominator expression\n",
    "    denominator = np.sum(visibility.astype(bool).astype(int))\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"DFDNet-EMA-kpts\" if EMA else \"DFDNet-kpts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6531/6531 [12:25<00:00,  8.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename=experiment_name,\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.DEBUG)\n",
    "\n",
    "logging.info(\"Running kpts comparison\")\n",
    "\n",
    "logger = logging.getLogger('DFDNet')\n",
    "\n",
    "pred_sum_rmse = 0.0\n",
    "pred_sum_de = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "pred_sum_oks = 0.0\n",
    "sr_sum_rmse = 0.0\n",
    "sr_sum_de = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "sr_sum_oks = 0.0\n",
    "\n",
    "pred_num_rmse = 0\n",
    "pred_num_de = 0\n",
    "pred_num_oks = 0\n",
    "sr_num_rmse = 0\n",
    "sr_num_de = 0\n",
    "sr_num_oks = 0\n",
    "\n",
    "model = model.to('cuda')\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "        \n",
    "    original_image = dataset[i]['img'] # tensor of shape (256, 256, 3)\n",
    "    original_kpts = dataset[i]['keypoints'] # tensor of shape (7, 2)\n",
    "    original_kpts = original_kpts * 256 # rescale with image size\n",
    "    # Append the tensor with a visibility flag\n",
    "    visibility = np.where(np.all((original_kpts >= 0) & (original_kpts <= 256), axis=1), 1.0, 0.0)\n",
    "    original_kpts = np.concatenate((original_kpts, visibility.reshape(-1, 1)), axis=1)\n",
    "    \n",
    "    face_bbox = dataset[i][\"face_bbox\"]\n",
    "    x0, y0, x1, y1 = face_bbox\n",
    "    face_width: float = (x1 - x0).item()\n",
    "    face_height: float = (y1 - y0).item()\n",
    "    \n",
    "    imname = str(dataset[i]['impath']).split('/')[-1]\n",
    "    img_idx = imname.split('.')[0]\n",
    "        \n",
    "    logger.info(\"Evaluating image \" + imname)\n",
    "    #logger.info(\"Original kpts = \" + str(original_kpts))\n",
    "    \n",
    "    scaled_image_path = os.path.join(pred_path, f'{img_idx}.jpeg')\n",
    "    with Image.open(scaled_image_path) as fp:\n",
    "        fp = fp.resize((256, 256), Image.BICUBIC) # bicubic interpolation\n",
    "        pred_image = np.array(fp, dtype=np.float32)\n",
    "        pred_image = pred_image / 256.0\n",
    "        pred_image = rearrange(pred_image, \"h w c -> c h w\")\n",
    "        pred_image = pred_image[0:3, :, :] # remove the alpha channel, if exists\n",
    "        pred_image = torch.from_numpy(pred_image).to('cuda')\n",
    "    if pred_image is None:\n",
    "        continue\n",
    "    \n",
    "    sr_image_path = os.path.join(sr_path, f'{img_idx}.png')\n",
    "    with Image.open(sr_image_path) as fp:\n",
    "        sr_image = np.array(fp, dtype=np.float32)\n",
    "        sr_image = sr_image / 256.0\n",
    "        sr_image = rearrange(sr_image, \"h w c -> c h w\")\n",
    "        sr_image = sr_image[0:3, :, :] # remove the alpha channel, if exists\n",
    "        sr_image = torch.from_numpy(sr_image).to('cuda')\n",
    "    if sr_image is None:\n",
    "        continue\n",
    "    \n",
    "    predictions = model([pred_image, sr_image])\n",
    "    pred_kpts: Tensor = predictions[0]['keypoints'] # tensor of shape (N, 17, 3)\n",
    "    pred_kpts_scores: Tensor = predictions[0]['keypoints_scores']\n",
    "    pred_scores: Tensor = predictions[0]['scores']\n",
    "    filtered_pred_kpts = filter_keypoints_per_person(pred_kpts, pred_kpts_scores, pred_scores)\n",
    "    if filtered_pred_kpts is not None:\n",
    "        filtered_pred_kpts = filtered_pred_kpts[0:7] # shape (7, 3)\n",
    "    else:\n",
    "        continue\n",
    "    #logger.info(\"Predicted kpts = \" + str(filtered_pred_kpts))\n",
    "    \n",
    "    sr_kpts: Tensor = predictions[1]['keypoints'] # tensor of shape (N, 17, 3)\n",
    "    sr_kpts_scores: Tensor = predictions[1]['keypoints_scores']\n",
    "    sr_scores: Tensor = predictions[1]['scores']\n",
    "    filtered_sr_kpts = filter_keypoints_per_person(sr_kpts, sr_kpts_scores, sr_scores)\n",
    "    if filtered_sr_kpts is not None:\n",
    "        filtered_sr_kpts = filtered_sr_kpts[0:7] # shape (7, 3)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    pred = filtered_pred_kpts.cpu().detach().numpy()\n",
    "    sr = filtered_sr_kpts.cpu().detach().numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Detection error PRED\n",
    "    for i in range(0, 7):\n",
    "        x, y, v = original_kpts[i]\n",
    "        x_hat, y_hat, v_hat = pred[i]\n",
    "        if v == 1 and v_hat == 1:\n",
    "            de_i: float = DE(x, y, x_hat, y_hat, face_width)\n",
    "            logger.info(f\"Pred DE for kpt {i} = {de_i}\")\n",
    "            pred_sum_de[i] += de_i\n",
    "            pred_num_de += 1\n",
    "        else:\n",
    "            logger.warning(\"No DE for kpt \" + str(i))    \n",
    "    \n",
    "    # Detection error SR\n",
    "    for i in range(0, 7):\n",
    "        x, y, v = original_kpts[i]\n",
    "        x_hat, y_hat, v_hat = sr[i]\n",
    "        if v == 1 and v_hat == 1:\n",
    "            de_i: float = DE(x, y, x_hat, y_hat, face_width)\n",
    "            logger.info(f\"SR DE for kpt {i} = {de_i}\")\n",
    "            sr_sum_de[i] += de_i\n",
    "            sr_num_de += 1\n",
    "        else:\n",
    "            logger.warning(\"No DE for kpt \" + str(i))    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # RMSE\n",
    "    rmse = RMSE(original_kpts, pred)\n",
    "    logger.info(\"PRED RMSE = \" + str(rmse))\n",
    "    if rmse is not None:\n",
    "        pred_sum_rmse += rmse\n",
    "        pred_num_rmse += 1\n",
    "    \n",
    "    # RMSE\n",
    "    rmse = RMSE(original_kpts, sr)\n",
    "    logger.info(\"SR RMSE = \" + str(rmse))\n",
    "    if rmse is not None:\n",
    "        sr_sum_rmse += rmse\n",
    "        sr_num_rmse += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    # OKS\n",
    "    oks: float = OKS(original_kpts[:, 0:1], pred[:, 0:1], original_kpts[:, 2].astype(int), (face_width * face_height))\n",
    "    logger.info(f'PRED OKS = {oks}')\n",
    "    pred_sum_oks += oks\n",
    "    pred_num_oks += 1\n",
    "    \n",
    "    # OKS\n",
    "    oks: float = OKS(original_kpts[:, 0:1], sr[:, 0:1], original_kpts[:, 2].astype(int), (face_width * face_height))\n",
    "    logger.info(f'SR OKS = {oks}')\n",
    "    sr_sum_oks += oks\n",
    "    sr_num_oks += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Compute averages\n",
    "pred_avg_rmse = pred_sum_rmse / pred_num_rmse\n",
    "pred_avg_de = [de_kpt / pred_num_de for de_kpt in pred_sum_de]\n",
    "pred_avg_oks = pred_sum_oks / pred_num_oks\n",
    "\n",
    "sr_avg_rmse = sr_sum_rmse / sr_num_rmse\n",
    "sr_avg_de = [de_kpt / sr_num_de for de_kpt in sr_sum_de]\n",
    "sr_avg_oks = sr_sum_oks / sr_num_oks\n",
    "\n",
    "logger.info(\"--------EVALUATION COMPLETE--------\")\n",
    "logger.info(f'Average RMSE: {pred_avg_rmse}')\n",
    "logger.info(f'Average DEs: {pred_avg_de}')\n",
    "logger.info(f'Average OKS: {pred_avg_oks}')\n",
    "logger.info(f'Average RMSE: {sr_avg_rmse}')\n",
    "logger.info(f'Average DEs: {sr_avg_de}')\n",
    "logger.info(f'Average OKS: {sr_avg_oks}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------EVALUATION COMPLETE--------\n",
      "Average RMSE: 30.958071430318856\n",
      "Average DEs: [0.027892838160655353, 0.025184058072169502, 0.026695445286606032, 0.04493417460006078, 0.04759476434332469, 0.002892176121812578, 0.004220795199165836]\n",
      "Average OKS: 0.3896908707629083\n",
      "Average RMSE: 16.649107928472986\n",
      "Average DEs: [0.010988184569279608, 0.010622688118413085, 0.010650759713635001, 0.025262061460247304, 0.024458929986516408, 0.003657863030239219, 0.005398846665224996]\n",
      "Average OKS: 0.567310674406386\n"
     ]
    }
   ],
   "source": [
    "print(\"--------EVALUATION COMPLETE--------\")\n",
    "print(f'Average RMSE: {pred_avg_rmse}')\n",
    "print(f'Average DEs: {pred_avg_de}')\n",
    "print(f'Average OKS: {pred_avg_oks}')\n",
    "print(f'Average RMSE: {sr_avg_rmse}')\n",
    "print(f'Average DEs: {sr_avg_de}')\n",
    "print(f'Average OKS: {sr_avg_oks}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facediffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
