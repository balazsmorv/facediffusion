{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating image metrics on face bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load pyspng. Defaulting to pillow image backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/datadrive/facediffusion')\n",
    "from fdh256_dataset import FDF256Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded from: /datadrive/FDF/dataset/val. Number of samples:6531\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '/datadrive/FDF/dataset/val'\n",
    "dataset = FDF256Dataset(dirpath=dataset_path, load_keypoints=True, load_impath=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMA = True # set to true to perform evaluation on the EMA model's generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EMA:\n",
    "    generated_ims_path = '/datadrive/facediffusion/Coginfocom/images-ema'\n",
    "    sr_ims_path = '/datadrive/facediffusion/Coginfocom/DFDNet-SR-Coginfocom-EMA'\n",
    "else:\n",
    "    generated_ims_path = '/datadrive/facediffusion/Coginfocom/images'\n",
    "    sr_ims_path = '/datadrive/facediffusion/Coginfocom/DFDNet-SR-Coginfocom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 13:55:44.134334: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-10 13:55:48.369464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename=\"EMA-DFDNet-BBOX\" if EMA else \"non-EMA-DFDNet-BBOX\",\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logging.info(\"Running image metrics comparison...\")\n",
    "logger = logging.getLogger('DFDNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6531 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Missing required positional argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m sr_img \u001b[39m=\u001b[39m sr_img\u001b[39m.\u001b[39mcrop((x0, y0, x1, y1)) \u001b[39m# crop to face bbox\u001b[39;00m\n\u001b[1;32m     29\u001b[0m sr_img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(sr_img)\n\u001b[0;32m---> 31\u001b[0m pred_im_psnr: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mpsnr(pred_img, original_img)\n\u001b[1;32m     32\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mimg_idx\u001b[39m}\u001b[39;00m\u001b[39m PRED PSNR \u001b[39m\u001b[39m{\u001b[39;00mpred_im_psnr\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m pred_im_ssim: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m ssim(im1\u001b[39m=\u001b[39moriginal_img, im2\u001b[39m=\u001b[39mpred_img, data_range\u001b[39m=\u001b[39mpred_img\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m pred_img\u001b[39m.\u001b[39mmin(), channel_axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m/datadrive/anaconda3/envs/facediffusion/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/datadrive/anaconda3/envs/facediffusion/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1170\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[39mif\u001b[39;00m iterable_params \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m   args, kwargs \u001b[39m=\u001b[39m replace_iterable_params(args, kwargs, iterable_params)\n\u001b[0;32m-> 1170\u001b[0m result \u001b[39m=\u001b[39m api_dispatcher\u001b[39m.\u001b[39;49mDispatch(args, kwargs)\n\u001b[1;32m   1171\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1172\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mTypeError\u001b[0m: Missing required positional argument"
     ]
    }
   ],
   "source": [
    "total_pred_psnr = 0.0\n",
    "total_pred_ssim = 0.0\n",
    "total_sr_psnr = 0.0\n",
    "total_sr_ssim = 0.0\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    \n",
    "    face_bbox = dataset[i][\"face_bbox\"]\n",
    "    x0, y0, x1, y1 = face_bbox\n",
    "    x0, y0, x1, y1 = x0.item(), y0.item(), x1.item(), y1.item()\n",
    "    \n",
    "    original_img = dataset[i][\"img\"]\n",
    "    original_img = Image.fromarray(original_img)\n",
    "    original_img = original_img.crop((x0, y0, x1, y1)) # crop to the face bbox\n",
    "    original_img.save(f'{i}_orig.png')\n",
    "    original_img = np.asarray(original_img)\n",
    "    img_name: str = str(dataset[i]['impath']).split('/')[-1]\n",
    "    img_idx = img_name.split('.')[0]\n",
    "    \n",
    "    pred_img_path = os.path.join(generated_ims_path, f'{img_idx}.jpeg')\n",
    "    pred_img = Image.open(pred_img_path)\n",
    "    pred_img = pred_img.resize((256, 256), Image.BICUBIC)\n",
    "    pred_img = pred_img.crop((x0, y0, x1, y1)) # crop to face bbox\n",
    "    pred_img = np.asarray(pred_img)\n",
    "    \n",
    "    sr_img_path = os.path.join(sr_ims_path, f'{img_idx}.png')\n",
    "    sr_img = Image.open(sr_img_path)\n",
    "    sr_img = sr_img.crop((x0, y0, x1, y1)) # crop to face bbox\n",
    "    sr_img = np.asarray(sr_img)\n",
    "    \n",
    "    pred_im_psnr: float = tf.image.psnr(pred_img, original_img, max_val=255)\n",
    "    logger.info(f'{img_idx} PRED PSNR {pred_im_psnr}')\n",
    "    pred_im_ssim: float = ssim(im1=original_img, im2=pred_img, data_range=pred_img.max() - pred_img.min(), channel_axis=2)\n",
    "    logger.info(f'{img_idx} PRED SSIM {pred_im_ssim}')\n",
    "    total_pred_psnr += pred_im_psnr\n",
    "    total_pred_ssim += pred_im_ssim\n",
    "    \n",
    "    sr_im_psnr: float = tf.image.psnr(sr_img, original_img, max_val=255)\n",
    "    logger.info(f'{img_idx} SR PSNR {sr_im_psnr}')\n",
    "    sr_im_ssim: float = ssim(im1=original_img, im2=sr_img, data_range=sr_img.max() - sr_img.min(), channel_axis=2)\n",
    "    logger.info(f'{img_idx} SR SSIM {sr_im_ssim}')\n",
    "    total_sr_psnr += sr_im_psnr\n",
    "    total_sr_ssim += sr_im_ssim\n",
    "    \n",
    "avg_pred_psnr = total_pred_psnr / len(dataset)\n",
    "avg_pred_ssim = total_pred_ssim / len(dataset)\n",
    "\n",
    "avg_sr_psnr = total_sr_psnr / len(dataset)\n",
    "avg_sr_ssim = total_sr_ssim / len(dataset)\n",
    "\n",
    "logger.info(f'Interpolated images PSNR = {avg_pred_psnr}')\n",
    "logger.info(f'SR images PSNR = {avg_sr_psnr}')\n",
    "logger.info(f'Interpolated images SSIM = {avg_pred_ssim}')\n",
    "logger.info(f'SR images SSIM = {avg_sr_ssim}')\n",
    "\n",
    "print(f'Interpolated images PSNR = {avg_pred_psnr}')\n",
    "print(f'SR images PSNR = {avg_sr_psnr}')\n",
    "print(f'Interpolated images SSIM = {avg_pred_ssim}')\n",
    "print(f'SR images SSIM = {avg_sr_ssim}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facediffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
