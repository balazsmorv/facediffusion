{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import keypointrcnn_resnet50_fpn, KeypointRCNN_ResNet50_FPN_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeypointRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(640, 672, 704, 736, 768, 800), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "    (keypoint_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (keypoint_head): KeypointRCNNHeads(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "    )\n",
       "    (keypoint_predictor): KeypointRCNNPredictor(\n",
       "      (kps_score_lowres): ConvTranspose2d(512, 17, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.detection.keypointrcnn_resnet50_fpn(weights=KeypointRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/home/oem/Letöltések/Facialexp'\n",
    "label_path = '/home/oem/Letöltések/Facialexp/labels_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pth</th>\n",
       "      <th>label</th>\n",
       "      <th>relFCs</th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>left_eye_x</th>\n",
       "      <th>left_eye_y</th>\n",
       "      <th>right_eye_x</th>\n",
       "      <th>right_eye_y</th>\n",
       "      <th>left_ear_x</th>\n",
       "      <th>...</th>\n",
       "      <th>right_ear_x</th>\n",
       "      <th>right_ear_y</th>\n",
       "      <th>left_sho_x</th>\n",
       "      <th>left_sho_y</th>\n",
       "      <th>right_sho_x</th>\n",
       "      <th>right_sho_y</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger/image0000006.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>0.873142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger/image0000060.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.852311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger/image0000061.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger/image0000066.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.843079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger/image0000106.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.849108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        pth  label    relFCs  nose_x  nose_y  left_eye_x  \\\n",
       "idx                                                                        \n",
       "0    anger/image0000006.jpg      7  0.873142     NaN     NaN         NaN   \n",
       "1    anger/image0000060.jpg      0  0.852311     NaN     NaN         NaN   \n",
       "2    anger/image0000061.jpg      0  0.800957     NaN     NaN         NaN   \n",
       "3    anger/image0000066.jpg      2  0.843079     NaN     NaN         NaN   \n",
       "4    anger/image0000106.jpg      0  0.849108     NaN     NaN         NaN   \n",
       "\n",
       "     left_eye_y  right_eye_x  right_eye_y  left_ear_x  ...  right_ear_x  \\\n",
       "idx                                                    ...                \n",
       "0           NaN          NaN          NaN         NaN  ...          NaN   \n",
       "1           NaN          NaN          NaN         NaN  ...          NaN   \n",
       "2           NaN          NaN          NaN         NaN  ...          NaN   \n",
       "3           NaN          NaN          NaN         NaN  ...          NaN   \n",
       "4           NaN          NaN          NaN         NaN  ...          NaN   \n",
       "\n",
       "     right_ear_y  left_sho_x  left_sho_y  right_sho_x  right_sho_y  x1  y1  \\\n",
       "idx                                                                          \n",
       "0            NaN         NaN         NaN          NaN          NaN NaN NaN   \n",
       "1            NaN         NaN         NaN          NaN          NaN NaN NaN   \n",
       "2            NaN         NaN         NaN          NaN          NaN NaN NaN   \n",
       "3            NaN         NaN         NaN          NaN          NaN NaN NaN   \n",
       "4            NaN         NaN         NaN          NaN          NaN NaN NaN   \n",
       "\n",
       "     x2  y2  \n",
       "idx          \n",
       "0   NaN NaN  \n",
       "1   NaN NaN  \n",
       "2   NaN NaN  \n",
       "3   NaN NaN  \n",
       "4   NaN NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels = pd.read_csv(label_path, index_col='idx', sep=';')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://learnopencv.com/human-pose-estimation-using-keypoint-rcnn-in-pytorch/, rewritten a bit\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def filter_keypoints_per_person(all_keypoints, all_scores, confs, bboxes, keypoint_threshold=0.7, conf_threshold=0.75):\n",
    "    kpts_dict = []\n",
    "    # iterate for every person detected\n",
    "    for person_id in range(len(all_keypoints)):\n",
    "      # check the confidence score of the detected person\n",
    "      if confs[person_id]>conf_threshold:\n",
    "        # grab the keypoint-locations for the detected person\n",
    "        keypoints:Tensor = all_keypoints[person_id, ...]\n",
    "        # grab the keypoint-scores for the keypoints\n",
    "        scores: Tensor = all_scores[person_id, ...]\n",
    "        # iterate for every keypoint-score\n",
    "        for kp in range(len(scores)):\n",
    "            # check the confidence score of detected keypoint\n",
    "            if torch.sigmoid(scores[kp]) < keypoint_threshold:\n",
    "                # convert the keypoint float-array to a python-list of integers\n",
    "                keypoints[kp, 2] = 0\n",
    "        kpts_dict.append({'conf': confs[person_id], 'kpts': keypoints, 'bbox': bboxes[person_id]})\n",
    "    \n",
    "    kpts_dict.sort(key=lambda x: x['conf'], reverse=True)\n",
    "    \n",
    "    return {'kpts': kpts_dict[0]['kpts'], 'bbox': kpts_dict[0]['bbox']} if len(kpts_dict) > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "class FacialExpressionsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.labels = pd.read_csv(csv_file, index_col='idx', sep=';')\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image_path = os.path.join(self.root_dir, self.labels.iloc[idx, 0])\n",
    "        image = Image.open(image_path)\n",
    "        image_tensor = TF.to_tensor(image)\n",
    "        \n",
    "        label = self.labels.iloc[idx, 1].astype('int')\n",
    "        impath = self.labels.iloc[idx, 0]\n",
    "        \n",
    "        keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
    "        keypoints = torch.reshape(keypoints, shape=(7, 2))\n",
    "        \n",
    "        bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
    "\n",
    "        sample = {'image': image_tensor, 'label': label, 'keypoints': keypoints, 'impath': impath, 'idx': idx, 'bbox': bounding_boxes}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FacialExpressionsDataset(csv_file=label_path, root_dir=data_folder, transform=None)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=8, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model output tensor is a 17x3 tensor, where the coordinates are the x, y, and visibility (0 is invisible, 1 is visible). The keypoints are:\n",
    "- nose\n",
    "- left eye\n",
    "- right eye\n",
    "- left ear\n",
    "- right ear\n",
    "- left shoulder\n",
    "- right shoulder\n",
    "- left elbow\n",
    "- right elbow\n",
    "- left wrist\n",
    "- right wrist\n",
    "- left hip\n",
    "- right hip\n",
    "- left knee\n",
    "- right knee\n",
    "- left ankle\n",
    "- right ankle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "  0%|          | 0/3522 [00:00<?, ?it/s]/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_36197/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_36197/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "100%|██████████| 3522/3522 [18:59<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints not found = 627, ratio = 0.17802385008517888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = model.cuda()\n",
    "keypoint_not_found = 0\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for i, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        images = batch['image'].cuda()\n",
    "        predictions = model(images)\n",
    "        for num, prediction in enumerate(predictions):\n",
    "            pred_kpts: Tensor = prediction['keypoints'] # tensor of shape (N, 17, 3)\n",
    "            pred_kpts_scores: Tensor = prediction['keypoints_scores']\n",
    "            pred_scores: Tensor = prediction['scores']\n",
    "            pred_bboxes: Tensor = prediction['boxes']\n",
    "            filtered_pred = filter_keypoints_per_person(pred_kpts, pred_kpts_scores, pred_scores, pred_bboxes)\n",
    "            if filtered_pred is None:\n",
    "                image_id = batch['impath'][num]\n",
    "                keypoint_not_found += 1\n",
    "                #print(f'Filtered kpts is None for image {image_id}')\n",
    "                continue\n",
    "            filtered_pred_kpts = filtered_pred['kpts']\n",
    "            filtered_pred_bbox = filtered_pred['bbox']\n",
    "            image_id = batch['idx'][num].item()\n",
    "            row = labels.iloc[image_id]\n",
    "            for kpt_id in range(7):\n",
    "                if filtered_pred_kpts[kpt_id][2].item() == 0:\n",
    "                    continue # keypoint invisible\n",
    "                labels.iloc[image_id, 3 + 2*kpt_id] = filtered_pred_kpts[kpt_id][0].item() / 96.0 # x\n",
    "                labels.iloc[image_id, 3 + 2*kpt_id + 1] = filtered_pred_kpts[kpt_id][1].item() / 96.0 # y\n",
    "            arr = np.array(filtered_pred_bbox.cpu()) / 96.0 # bbox x1, y1, x2, y2\n",
    "            labels.iloc[image_id, -4:] = arr\n",
    "\n",
    "print(f\"Keypoints not found = {keypoint_not_found}, ratio = {keypoint_not_found / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()\n",
    "labels.to_csv(path_or_buf='/home/oem/Letöltések/Facialexp/labels_with_kpts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping a total of 696\n",
      "Dropping a total of 812\n"
     ]
    }
   ],
   "source": [
    "dflen = len(labels)\n",
    "labels_filtered = labels[labels.nose_x.notnull()]\n",
    "print(f'Dropping a total of {dflen - len(labels_filtered)}')\n",
    "labels_filtered = labels_filtered[labels_filtered.nose_y.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.left_eye_x.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.left_eye_y.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.right_eye_x.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.right_eye_y.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.left_ear_x.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.left_ear_y.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.right_ear_x.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.right_ear_y.notnull()]\n",
    "print(f'Dropping a total of {dflen - len(labels_filtered)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>relFCs</th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>left_eye_x</th>\n",
       "      <th>left_eye_y</th>\n",
       "      <th>right_eye_x</th>\n",
       "      <th>right_eye_y</th>\n",
       "      <th>left_ear_x</th>\n",
       "      <th>left_ear_y</th>\n",
       "      <th>right_ear_x</th>\n",
       "      <th>right_ear_y</th>\n",
       "      <th>left_sho_x</th>\n",
       "      <th>left_sho_y</th>\n",
       "      <th>right_sho_x</th>\n",
       "      <th>right_sho_y</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>7231.000000</td>\n",
       "      <td>7231.000000</td>\n",
       "      <td>11072.000000</td>\n",
       "      <td>11072.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.612652</td>\n",
       "      <td>0.798932</td>\n",
       "      <td>0.502271</td>\n",
       "      <td>0.575425</td>\n",
       "      <td>0.628848</td>\n",
       "      <td>0.437048</td>\n",
       "      <td>0.378033</td>\n",
       "      <td>0.440502</td>\n",
       "      <td>0.792719</td>\n",
       "      <td>0.533937</td>\n",
       "      <td>0.220019</td>\n",
       "      <td>0.534760</td>\n",
       "      <td>0.848383</td>\n",
       "      <td>0.884613</td>\n",
       "      <td>0.156329</td>\n",
       "      <td>0.896281</td>\n",
       "      <td>0.076231</td>\n",
       "      <td>0.061008</td>\n",
       "      <td>0.925355</td>\n",
       "      <td>0.982712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.342842</td>\n",
       "      <td>0.058639</td>\n",
       "      <td>0.066170</td>\n",
       "      <td>0.063973</td>\n",
       "      <td>0.074071</td>\n",
       "      <td>0.059611</td>\n",
       "      <td>0.079960</td>\n",
       "      <td>0.064732</td>\n",
       "      <td>0.129359</td>\n",
       "      <td>0.103680</td>\n",
       "      <td>0.137101</td>\n",
       "      <td>0.109025</td>\n",
       "      <td>0.134115</td>\n",
       "      <td>0.134917</td>\n",
       "      <td>0.128549</td>\n",
       "      <td>0.122077</td>\n",
       "      <td>0.093367</td>\n",
       "      <td>0.079447</td>\n",
       "      <td>0.093848</td>\n",
       "      <td>0.026382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516357</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091871</td>\n",
       "      <td>0.136066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.766139</td>\n",
       "      <td>0.480781</td>\n",
       "      <td>0.554979</td>\n",
       "      <td>0.621340</td>\n",
       "      <td>0.404855</td>\n",
       "      <td>0.351246</td>\n",
       "      <td>0.407430</td>\n",
       "      <td>0.755569</td>\n",
       "      <td>0.475988</td>\n",
       "      <td>0.149587</td>\n",
       "      <td>0.475326</td>\n",
       "      <td>0.810736</td>\n",
       "      <td>0.857546</td>\n",
       "      <td>0.069513</td>\n",
       "      <td>0.876388</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.898158</td>\n",
       "      <td>0.977322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.808588</td>\n",
       "      <td>0.501875</td>\n",
       "      <td>0.581360</td>\n",
       "      <td>0.632963</td>\n",
       "      <td>0.434604</td>\n",
       "      <td>0.369813</td>\n",
       "      <td>0.436637</td>\n",
       "      <td>0.807141</td>\n",
       "      <td>0.535065</td>\n",
       "      <td>0.202727</td>\n",
       "      <td>0.535228</td>\n",
       "      <td>0.884897</td>\n",
       "      <td>0.923363</td>\n",
       "      <td>0.125205</td>\n",
       "      <td>0.935202</td>\n",
       "      <td>0.043029</td>\n",
       "      <td>0.035198</td>\n",
       "      <td>0.955791</td>\n",
       "      <td>0.986520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.841750</td>\n",
       "      <td>0.524120</td>\n",
       "      <td>0.604199</td>\n",
       "      <td>0.652838</td>\n",
       "      <td>0.464929</td>\n",
       "      <td>0.382110</td>\n",
       "      <td>0.465447</td>\n",
       "      <td>0.863879</td>\n",
       "      <td>0.585270</td>\n",
       "      <td>0.252899</td>\n",
       "      <td>0.586928</td>\n",
       "      <td>0.929205</td>\n",
       "      <td>0.959375</td>\n",
       "      <td>0.210482</td>\n",
       "      <td>0.958926</td>\n",
       "      <td>0.106067</td>\n",
       "      <td>0.082886</td>\n",
       "      <td>0.984961</td>\n",
       "      <td>0.994555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.899951</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.992028</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.978926</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>0.982659</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.999164</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>0.998128</td>\n",
       "      <td>0.996641</td>\n",
       "      <td>0.998128</td>\n",
       "      <td>0.922501</td>\n",
       "      <td>0.864619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        relFCs        nose_x        nose_y    left_eye_x  \\\n",
       "count  27363.000000  27363.000000  27363.000000  27363.000000  27363.000000   \n",
       "mean       3.612652      0.798932      0.502271      0.575425      0.628848   \n",
       "std        2.342842      0.058639      0.066170      0.063973      0.074071   \n",
       "min        0.000000      0.516357      0.000623      0.001655      0.000623   \n",
       "25%        2.000000      0.766139      0.480781      0.554979      0.621340   \n",
       "50%        4.000000      0.808588      0.501875      0.581360      0.632963   \n",
       "75%        6.000000      0.841750      0.524120      0.604199      0.652838   \n",
       "max        7.000000      0.899951      0.999378      0.992028      0.999378   \n",
       "\n",
       "         left_eye_y   right_eye_x   right_eye_y    left_ear_x    left_ear_y  \\\n",
       "count  27363.000000  27363.000000  27363.000000  27363.000000  27363.000000   \n",
       "mean       0.437048      0.378033      0.440502      0.792719      0.533937   \n",
       "std        0.059611      0.079960      0.064732      0.129359      0.103680   \n",
       "min        0.000625      0.000624      0.001655      0.000624      0.001973   \n",
       "25%        0.404855      0.351246      0.407430      0.755569      0.475988   \n",
       "50%        0.434604      0.369813      0.436637      0.807141      0.535065   \n",
       "75%        0.464929      0.382110      0.465447      0.863879      0.585270   \n",
       "max        0.978926      0.999377      0.982659      0.999377      0.984907   \n",
       "\n",
       "        right_ear_x   right_ear_y   left_sho_x   left_sho_y   right_sho_x  \\\n",
       "count  27363.000000  27363.000000  7231.000000  7231.000000  11072.000000   \n",
       "mean       0.220019      0.534760     0.848383     0.884613      0.156329   \n",
       "std        0.137101      0.109025     0.134115     0.134917      0.128549   \n",
       "min        0.000621      0.001655     0.000623     0.003121      0.000623   \n",
       "25%        0.149587      0.475326     0.810736     0.857546      0.069513   \n",
       "50%        0.202727      0.535228     0.884897     0.923363      0.125205   \n",
       "75%        0.252899      0.586928     0.929205     0.959375      0.210482   \n",
       "max        0.999164      0.996875     0.999377     0.998128      0.996641   \n",
       "\n",
       "        right_sho_y            x1            y1            x2            y2  \n",
       "count  11072.000000  27363.000000  27363.000000  27363.000000  27363.000000  \n",
       "mean       0.896281      0.076231      0.061008      0.925355      0.982712  \n",
       "std        0.122077      0.093367      0.079447      0.093848      0.026382  \n",
       "min        0.001872      0.000000      0.000000      0.091871      0.136066  \n",
       "25%        0.876388      0.015373      0.006300      0.898158      0.977322  \n",
       "50%        0.935202      0.043029      0.035198      0.955791      0.986520  \n",
       "75%        0.958926      0.106067      0.082886      0.984961      0.994555  \n",
       "max        0.998128      0.922501      0.864619      1.000000      1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filtered.to_csv(path_or_buf='/home/oem/Letöltések/Facialexp/labels_with_kpts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facediffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
