{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oem/anaconda3/envs/facediffusion/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import keypointrcnn_resnet50_fpn, KeypointRCNN_ResNet50_FPN_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeypointRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(640, 672, 704, 736, 768, 800), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "    (keypoint_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (keypoint_head): KeypointRCNNHeads(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "    )\n",
       "    (keypoint_predictor): KeypointRCNNPredictor(\n",
       "      (kps_score_lowres): ConvTranspose2d(512, 17, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.detection.keypointrcnn_resnet50_fpn(weights=KeypointRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/home/oem/Letöltések/Facialexp'\n",
    "label_path = '/home/oem/Letöltések/Facialexp/labels_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pth</th>\n",
       "      <th>label</th>\n",
       "      <th>relFCs</th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>left_eye_x</th>\n",
       "      <th>left_eye_y</th>\n",
       "      <th>right_eye_x</th>\n",
       "      <th>right_eye_y</th>\n",
       "      <th>left_ear_x</th>\n",
       "      <th>...</th>\n",
       "      <th>right_ear_x</th>\n",
       "      <th>right_ear_y</th>\n",
       "      <th>left_sho_x</th>\n",
       "      <th>left_sho_y</th>\n",
       "      <th>right_sho_x</th>\n",
       "      <th>right_sho_y</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger/image0000006.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>0.873142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger/image0000060.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.852311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger/image0000061.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger/image0000066.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.843079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger/image0000106.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.849108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        pth  label    relFCs  nose_x  nose_y  left_eye_x  \\\n",
       "idx                                                                        \n",
       "0    anger/image0000006.jpg      7  0.873142     NaN     NaN         NaN   \n",
       "1    anger/image0000060.jpg      0  0.852311     NaN     NaN         NaN   \n",
       "2    anger/image0000061.jpg      0  0.800957     NaN     NaN         NaN   \n",
       "3    anger/image0000066.jpg      2  0.843079     NaN     NaN         NaN   \n",
       "4    anger/image0000106.jpg      0  0.849108     NaN     NaN         NaN   \n",
       "\n",
       "     left_eye_y  right_eye_x  right_eye_y  left_ear_x  ...  right_ear_x  \\\n",
       "idx                                                    ...                \n",
       "0           NaN          NaN          NaN         NaN  ...          NaN   \n",
       "1           NaN          NaN          NaN         NaN  ...          NaN   \n",
       "2           NaN          NaN          NaN         NaN  ...          NaN   \n",
       "3           NaN          NaN          NaN         NaN  ...          NaN   \n",
       "4           NaN          NaN          NaN         NaN  ...          NaN   \n",
       "\n",
       "     right_ear_y  left_sho_x  left_sho_y  right_sho_x  right_sho_y  x1  y1  \\\n",
       "idx                                                                          \n",
       "0            NaN         NaN         NaN          NaN          NaN NaN NaN   \n",
       "1            NaN         NaN         NaN          NaN          NaN NaN NaN   \n",
       "2            NaN         NaN         NaN          NaN          NaN NaN NaN   \n",
       "3            NaN         NaN         NaN          NaN          NaN NaN NaN   \n",
       "4            NaN         NaN         NaN          NaN          NaN NaN NaN   \n",
       "\n",
       "     x2  y2  \n",
       "idx          \n",
       "0   NaN NaN  \n",
       "1   NaN NaN  \n",
       "2   NaN NaN  \n",
       "3   NaN NaN  \n",
       "4   NaN NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels = pd.read_csv(label_path, index_col='idx', sep=';')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://learnopencv.com/human-pose-estimation-using-keypoint-rcnn-in-pytorch/, rewritten a bit\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def filter_keypoints_per_person(all_keypoints, all_scores, confs, bboxes, keypoint_threshold=0.7, conf_threshold=0.75):\n",
    "    kpts_dict = []\n",
    "    # iterate for every person detected\n",
    "    for person_id in range(len(all_keypoints)):\n",
    "      # check the confidence score of the detected person\n",
    "      if confs[person_id]>conf_threshold:\n",
    "        # grab the keypoint-locations for the detected person\n",
    "        keypoints:Tensor = all_keypoints[person_id, ...]\n",
    "        # grab the keypoint-scores for the keypoints\n",
    "        scores: Tensor = all_scores[person_id, ...]\n",
    "        # iterate for every keypoint-score\n",
    "        for kp in range(len(scores)):\n",
    "            # check the confidence score of detected keypoint\n",
    "            if torch.sigmoid(scores[kp]) < keypoint_threshold:\n",
    "                # convert the keypoint float-array to a python-list of integers\n",
    "                keypoints[kp, 2] = 0\n",
    "        kpts_dict.append({'conf': confs[person_id], 'kpts': keypoints, 'bbox': bboxes[person_id]})\n",
    "    \n",
    "    kpts_dict.sort(key=lambda x: x['conf'], reverse=True)\n",
    "    \n",
    "    return {'kpts': kpts_dict[0]['kpts'], 'bbox': kpts_dict[0]['bbox']} if len(kpts_dict) > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "class FacialExpressionsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.labels = pd.read_csv(csv_file, index_col='idx', sep=';')\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image_path = os.path.join(self.root_dir, self.labels.iloc[idx, 0])\n",
    "        image = Image.open(image_path)\n",
    "        image_tensor = TF.to_tensor(image)\n",
    "        \n",
    "        label = self.labels.iloc[idx, 1].astype('int')\n",
    "        impath = self.labels.iloc[idx, 0]\n",
    "        \n",
    "        keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
    "        keypoints = torch.reshape(keypoints, shape=(7, 2))\n",
    "        \n",
    "        bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
    "\n",
    "        sample = {'image': image_tensor, 'label': label, 'keypoints': keypoints, 'impath': impath, 'idx': idx, 'bbox': bounding_boxes}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FacialExpressionsDataset(csv_file=label_path, root_dir=data_folder, transform=None)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=8, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model output tensor is a 17x3 tensor, where the coordinates are the x, y, and visibility (0 is invisible, 1 is visible). The keypoints are:\n",
    "- nose\n",
    "- left eye\n",
    "- right eye\n",
    "- left ear\n",
    "- right ear\n",
    "- left shoulder\n",
    "- right shoulder\n",
    "- left elbow\n",
    "- right elbow\n",
    "- left wrist\n",
    "- right wrist\n",
    "- left hip\n",
    "- right hip\n",
    "- left knee\n",
    "- right knee\n",
    "- left ankle\n",
    "- right ankle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3522 [00:00<?, ?it/s]/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  keypoints = torch.tensor(data=[self.labels.iloc[idx, 3:17]])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "/tmp/ipykernel_6490/769515626.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  bounding_boxes = torch.tensor(data=self.labels.iloc[idx, 17:])\n",
      "100%|██████████| 3522/3522 [18:59<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints not found = 627, ratio = 0.17802385008517888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = model.cuda()\n",
    "keypoint_not_found = 0\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for i, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        images = batch['image'].cuda()\n",
    "        predictions = model(images)\n",
    "        for num, prediction in enumerate(predictions):\n",
    "            pred_kpts: Tensor = prediction['keypoints'] # tensor of shape (N, 17, 3)\n",
    "            pred_kpts_scores: Tensor = prediction['keypoints_scores']\n",
    "            pred_scores: Tensor = prediction['scores']\n",
    "            pred_bboxes: Tensor = prediction['boxes']\n",
    "            filtered_pred = filter_keypoints_per_person(pred_kpts, pred_kpts_scores, pred_scores, pred_bboxes)\n",
    "            if filtered_pred is None:\n",
    "                image_id = batch['impath'][num]\n",
    "                keypoint_not_found += 1\n",
    "                #print(f'Filtered kpts is None for image {image_id}')\n",
    "                continue\n",
    "            filtered_pred_kpts = filtered_pred['kpts']\n",
    "            filtered_pred_bbox = filtered_pred['bbox']\n",
    "            image_id = batch['idx'][num].item()\n",
    "            row = labels.iloc[image_id]\n",
    "            for kpt_id in range(7):\n",
    "                if filtered_pred_kpts[kpt_id][2].item() == 0:\n",
    "                    continue # keypoint invisible\n",
    "                labels.iloc[image_id, 3 + 2*kpt_id] = filtered_pred_kpts[kpt_id][0].item() # x\n",
    "                labels.iloc[image_id, 3 + 2*kpt_id + 1] = filtered_pred_kpts[kpt_id][1].item() # y\n",
    "            arr = np.array(filtered_pred_bbox.cpu()) # bbox x1, y1, x2, y2\n",
    "            labels.iloc[image_id, -4:] = arr\n",
    "\n",
    "print(f\"Keypoints not found = {keypoint_not_found}, ratio = {keypoint_not_found / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()\n",
    "labels.to_csv(path_or_buf='/home/oem/Letöltések/Facialexp/labels_with_kpts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping a total of 696\n",
      "Dropping a total of 812\n"
     ]
    }
   ],
   "source": [
    "dflen = len(labels)\n",
    "labels_filtered = labels[labels.nose_x.notnull()]\n",
    "print(f'Dropping a total of {dflen - len(labels_filtered)}')\n",
    "labels_filtered = labels_filtered[labels_filtered.nose_y.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.left_eye_x.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.left_eye_y.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.right_eye_x.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.right_eye_y.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.left_ear_x.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.left_ear_y.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.right_ear_x.notnull()]\n",
    "labels_filtered = labels_filtered[labels_filtered.right_ear_y.notnull()]\n",
    "print(f'Dropping a total of {dflen - len(labels_filtered)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>relFCs</th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>left_eye_x</th>\n",
       "      <th>left_eye_y</th>\n",
       "      <th>right_eye_x</th>\n",
       "      <th>right_eye_y</th>\n",
       "      <th>left_ear_x</th>\n",
       "      <th>left_ear_y</th>\n",
       "      <th>right_ear_x</th>\n",
       "      <th>right_ear_y</th>\n",
       "      <th>left_sho_x</th>\n",
       "      <th>left_sho_y</th>\n",
       "      <th>right_sho_x</th>\n",
       "      <th>right_sho_y</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>7231.000000</td>\n",
       "      <td>7231.000000</td>\n",
       "      <td>11072.000000</td>\n",
       "      <td>11072.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "      <td>27363.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.612652</td>\n",
       "      <td>0.798932</td>\n",
       "      <td>48.218030</td>\n",
       "      <td>55.240801</td>\n",
       "      <td>60.369376</td>\n",
       "      <td>41.956625</td>\n",
       "      <td>36.291123</td>\n",
       "      <td>42.288217</td>\n",
       "      <td>76.101044</td>\n",
       "      <td>51.257967</td>\n",
       "      <td>21.121819</td>\n",
       "      <td>51.336995</td>\n",
       "      <td>81.444746</td>\n",
       "      <td>84.922888</td>\n",
       "      <td>15.007583</td>\n",
       "      <td>86.042993</td>\n",
       "      <td>7.318223</td>\n",
       "      <td>5.856727</td>\n",
       "      <td>88.834068</td>\n",
       "      <td>94.340378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.342842</td>\n",
       "      <td>0.058639</td>\n",
       "      <td>6.352322</td>\n",
       "      <td>6.141401</td>\n",
       "      <td>7.110814</td>\n",
       "      <td>5.722672</td>\n",
       "      <td>7.676114</td>\n",
       "      <td>6.214320</td>\n",
       "      <td>12.418442</td>\n",
       "      <td>9.953237</td>\n",
       "      <td>13.161733</td>\n",
       "      <td>10.466435</td>\n",
       "      <td>12.875064</td>\n",
       "      <td>12.952017</td>\n",
       "      <td>12.340749</td>\n",
       "      <td>11.719368</td>\n",
       "      <td>8.963269</td>\n",
       "      <td>7.626872</td>\n",
       "      <td>9.009366</td>\n",
       "      <td>2.532645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516357</td>\n",
       "      <td>0.059808</td>\n",
       "      <td>0.158888</td>\n",
       "      <td>0.059802</td>\n",
       "      <td>0.059991</td>\n",
       "      <td>0.059869</td>\n",
       "      <td>0.158888</td>\n",
       "      <td>0.059907</td>\n",
       "      <td>0.189404</td>\n",
       "      <td>0.059631</td>\n",
       "      <td>0.158888</td>\n",
       "      <td>0.059776</td>\n",
       "      <td>0.299662</td>\n",
       "      <td>0.059788</td>\n",
       "      <td>0.179679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.819621</td>\n",
       "      <td>13.062330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.766139</td>\n",
       "      <td>46.155012</td>\n",
       "      <td>53.277985</td>\n",
       "      <td>59.648626</td>\n",
       "      <td>38.866083</td>\n",
       "      <td>33.719639</td>\n",
       "      <td>39.113327</td>\n",
       "      <td>72.534622</td>\n",
       "      <td>45.694881</td>\n",
       "      <td>14.360335</td>\n",
       "      <td>45.631310</td>\n",
       "      <td>77.830639</td>\n",
       "      <td>82.324413</td>\n",
       "      <td>6.673236</td>\n",
       "      <td>84.133270</td>\n",
       "      <td>1.475823</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>86.223171</td>\n",
       "      <td>93.822941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.808588</td>\n",
       "      <td>48.180000</td>\n",
       "      <td>55.810574</td>\n",
       "      <td>60.764473</td>\n",
       "      <td>41.721992</td>\n",
       "      <td>35.502094</td>\n",
       "      <td>41.917191</td>\n",
       "      <td>77.485573</td>\n",
       "      <td>51.366257</td>\n",
       "      <td>19.461830</td>\n",
       "      <td>51.381924</td>\n",
       "      <td>84.950096</td>\n",
       "      <td>88.642868</td>\n",
       "      <td>12.019644</td>\n",
       "      <td>89.779373</td>\n",
       "      <td>4.130826</td>\n",
       "      <td>3.379025</td>\n",
       "      <td>91.755928</td>\n",
       "      <td>94.705902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.841750</td>\n",
       "      <td>50.315552</td>\n",
       "      <td>58.003139</td>\n",
       "      <td>62.672415</td>\n",
       "      <td>44.633158</td>\n",
       "      <td>36.682531</td>\n",
       "      <td>44.682924</td>\n",
       "      <td>82.932369</td>\n",
       "      <td>56.185884</td>\n",
       "      <td>24.278262</td>\n",
       "      <td>56.345064</td>\n",
       "      <td>89.203693</td>\n",
       "      <td>92.099998</td>\n",
       "      <td>20.206264</td>\n",
       "      <td>92.056850</td>\n",
       "      <td>10.182467</td>\n",
       "      <td>7.957049</td>\n",
       "      <td>94.556267</td>\n",
       "      <td>95.477303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.899951</td>\n",
       "      <td>95.940254</td>\n",
       "      <td>95.234734</td>\n",
       "      <td>95.940254</td>\n",
       "      <td>93.976944</td>\n",
       "      <td>95.940216</td>\n",
       "      <td>94.335266</td>\n",
       "      <td>95.940239</td>\n",
       "      <td>94.551033</td>\n",
       "      <td>95.919724</td>\n",
       "      <td>95.699997</td>\n",
       "      <td>95.940170</td>\n",
       "      <td>95.820274</td>\n",
       "      <td>95.677528</td>\n",
       "      <td>95.820290</td>\n",
       "      <td>88.560104</td>\n",
       "      <td>83.003395</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        relFCs        nose_x        nose_y    left_eye_x  \\\n",
       "count  27363.000000  27363.000000  27363.000000  27363.000000  27363.000000   \n",
       "mean       3.612652      0.798932     48.218030     55.240801     60.369376   \n",
       "std        2.342842      0.058639      6.352322      6.141401      7.110814   \n",
       "min        0.000000      0.516357      0.059808      0.158888      0.059802   \n",
       "25%        2.000000      0.766139     46.155012     53.277985     59.648626   \n",
       "50%        4.000000      0.808588     48.180000     55.810574     60.764473   \n",
       "75%        6.000000      0.841750     50.315552     58.003139     62.672415   \n",
       "max        7.000000      0.899951     95.940254     95.234734     95.940254   \n",
       "\n",
       "         left_eye_y   right_eye_x   right_eye_y    left_ear_x    left_ear_y  \\\n",
       "count  27363.000000  27363.000000  27363.000000  27363.000000  27363.000000   \n",
       "mean      41.956625     36.291123     42.288217     76.101044     51.257967   \n",
       "std        5.722672      7.676114      6.214320     12.418442      9.953237   \n",
       "min        0.059991      0.059869      0.158888      0.059907      0.189404   \n",
       "25%       38.866083     33.719639     39.113327     72.534622     45.694881   \n",
       "50%       41.721992     35.502094     41.917191     77.485573     51.366257   \n",
       "75%       44.633158     36.682531     44.682924     82.932369     56.185884   \n",
       "max       93.976944     95.940216     94.335266     95.940239     94.551033   \n",
       "\n",
       "        right_ear_x   right_ear_y   left_sho_x   left_sho_y   right_sho_x  \\\n",
       "count  27363.000000  27363.000000  7231.000000  7231.000000  11072.000000   \n",
       "mean      21.121819     51.336995    81.444746    84.922888     15.007583   \n",
       "std       13.161733     10.466435    12.875064    12.952017     12.340749   \n",
       "min        0.059631      0.158888     0.059776     0.299662      0.059788   \n",
       "25%       14.360335     45.631310    77.830639    82.324413      6.673236   \n",
       "50%       19.461830     51.381924    84.950096    88.642868     12.019644   \n",
       "75%       24.278262     56.345064    89.203693    92.099998     20.206264   \n",
       "max       95.919724     95.699997    95.940170    95.820274     95.677528   \n",
       "\n",
       "        right_sho_y            x1            y1            x2            y2  \n",
       "count  11072.000000  27363.000000  27363.000000  27363.000000  27363.000000  \n",
       "mean      86.042993      7.318223      5.856727     88.834068     94.340378  \n",
       "std       11.719368      8.963269      7.626872      9.009366      2.532645  \n",
       "min        0.179679      0.000000      0.000000      8.819621     13.062330  \n",
       "25%       84.133270      1.475823      0.604796     86.223171     93.822941  \n",
       "50%       89.779373      4.130826      3.379025     91.755928     94.705902  \n",
       "75%       92.056850     10.182467      7.957049     94.556267     95.477303  \n",
       "max       95.820290     88.560104     83.003395     96.000000     96.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filtered.to_csv(path_or_buf='/home/oem/Letöltések/Facialexp/labels_with_kpts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facediffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
